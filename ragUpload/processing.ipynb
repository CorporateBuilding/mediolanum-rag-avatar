{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "import datetime\n",
    "import streamlit as st\n",
    "import tempfile\n",
    "import os\n",
    "import time\n",
    "import conf\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from openai import AzureOpenAI\n",
    "from extractText.textProcessing import extractPdfsFromDir\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from extractText.textProcessing import extract_from_pdf\n",
    "from extractText.advancedProcessing import intelligentExtractPdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Devuelve pdf con la siguiente estructura pdf = { \"path\": path, \"pages\": [ num, text, tables] }}\n",
    "def extractSelectorPdf(pdfPath):\n",
    "    pdfData = extract_from_pdf(pdfPath) #TODO DIFERENCIAR POR DOCINTELLIGENCE MEJOR\n",
    "    detected_characters = sum(len(page[\"text\"]) for page in pdfData[\"pages\"])\n",
    "    pages = len(pdfData)\n",
    "\n",
    "    if detected_characters >= pages*conf.UMBRAL_MIN_CHARS_PER_PAGE:\n",
    "        print(\"\\t\\tPROCESADO NORMAL\")\n",
    "    else:\n",
    "        print(\"\\t\\tPROCESANDO DEEP\")\n",
    "        pdfData = intelligentExtractPdf(pdfPath) #TODO quitar\n",
    "        exit(\"ERRORRORORORO\")\n",
    "    \n",
    "    return pdfData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that extracts metadata from PDF file path\n",
    "# Parameters: pdf_path (str) - Path to the PDF file\n",
    "# Returns: dict - Metadata including filename, path, size and dates\n",
    "def extract_filename_metadata(pdf_path):\n",
    "    full_filename = os.path.basename(pdf_path)\n",
    "    filename_without_ext = os.path.splitext(full_filename)[0]\n",
    "    file_extension = os.path.splitext(full_filename)[1]\n",
    "    absolute_path = os.path.abspath(pdf_path)\n",
    "    \n",
    "    file_stats = os.stat(pdf_path)\n",
    "    file_size = file_stats.st_size\n",
    "    last_modified = datetime.datetime.fromtimestamp(file_stats.st_mtime).isoformat()\n",
    "    \n",
    "    metadata = {\n",
    "        \"filename\": full_filename,\n",
    "        \"filename_without_extension\": filename_without_ext,\n",
    "        \"file_extension\": file_extension,\n",
    "        \"file_path\": absolute_path,\n",
    "        \"file_size_bytes\": file_size,\n",
    "        \"last_modified\": last_modified,\n",
    "        \"extraction_time\": datetime.datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<(P3)>\n"
     ]
    }
   ],
   "source": [
    "print(conf.PAGE_IDENTIFIER.format(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getJustTextFromPdf(pdfStruct):\n",
    "    string = \"\"\n",
    "    \n",
    "    for i, page in enumerate(pdfStruct[\"pages\"]): \n",
    "        string += conf.PAGE_IDENTIFIER.format(i)\n",
    "        string += page[\"text\"] \n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def getTextFromVtt(vttPath):\n",
    "    texto = \"\"\n",
    "    \n",
    "    with open(vttPath, \"r\", encoding=\"utf-8\") as f:\n",
    "        texto = f.read()\n",
    "\n",
    "    regex = r\"\\n\\n[0-9a-f]{8}-([0-9a-f]{4}-){3}[0-9a-f]{12}-\\d*\\n[0-9:.]* --> [0-9:.]*\\n\"\n",
    "    result = re.sub(regex, \"\", texto)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import uuid\n",
    "\n",
    "# Function that loads text vectors into a QDrant database\n",
    "# Parameters: text (str), embedder, qdrant, collection_name (str), pdf_metadata (dict, optional)\n",
    "# Returns: int - Number of chunks added\n",
    "def uploadQdrantFromText(text, embedder, qdrant, collection_name, pdf_metadata=None, page_id_re : str = conf.PAGE_IDENTIFIER_RE):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=500)\n",
    "\n",
    "    collectionExists = qdrant.collection_exists(collection_name=collection_name)\n",
    "    \n",
    "    if not collectionExists:\n",
    "        qdrant.create_collection(\n",
    "            collection_name=collection_name,\n",
    "            vectors_config=models.VectorParams(size=1536, distance=models.Distance.COSINE)\n",
    "        )\n",
    "    \n",
    "    chunks = text_splitter.split_text(text)\n",
    "    embeddings = embedder.embed_documents(chunks)\n",
    "\n",
    "    total_points = qdrant.get_collection(collection_name).points_count\n",
    "    \n",
    "    points = []\n",
    "\n",
    "    num_pags = [0]\n",
    "\n",
    "    for id, (vector, chunk) in enumerate(zip(embeddings, chunks)):\n",
    "        payload = {\"text\": chunk}\n",
    "\n",
    "        pags = re.findall(page_id_re, chunk) #EXP REGULAR que muestra los números de página TODO: mejores formas de hacerlo\n",
    "        \n",
    "        num_pags = pags if pags != [] else num_pags\n",
    "\n",
    "        if num_pags != []:\n",
    "            pdf_metadata[\"indexer\"] = str(num_pags[0]) + \"-\" + str(num_pags[len(num_pags)-1])\n",
    "        \n",
    "        if pdf_metadata:\n",
    "            payload[\"metadata\"] = pdf_metadata\n",
    "            payload[\"source_file\"] = pdf_metadata[\"filename\"]\n",
    "\n",
    "        points.append({\n",
    "            \"id\": int(hash(chunk)) & (2**64 - 1),\n",
    "            \"vector\": vector,\n",
    "            \"payload\": payload\n",
    "        })\n",
    "    qdrant.upsert(\n",
    "        collection_name=collection_name,\n",
    "        points=points\n",
    "    )\n",
    "    \n",
    "    return len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre: dir = directorio del que extraer PDFs relative path from this function's file\n",
    "#Post: List con SOLO TEXTO de PDFs TODO IMAGENES\n",
    "def extractDataFromDir(dir: str, embedder, qdrant, collection_name):\n",
    "    \n",
    "    currentDir = os.getcwd()\n",
    "    dataDir = os.path.join(currentDir, dir)\n",
    "    dataList = []; pdfList = []\n",
    "    totalFiles = len(os.listdir(dataDir))\n",
    "\n",
    "    for i, file in enumerate(os.listdir(dataDir)):\n",
    "        \n",
    "        print(f\"PROCESANDO {i+1}/{totalFiles}: {file}\")\n",
    "        filePath = os.path.join(dataDir, file)\n",
    "        \n",
    "        if not os.path.isfile(filePath):\n",
    "            print(\"ERROR NOT FILE: \", filePath)\n",
    "            continue\n",
    "\n",
    "        metadata = extract_filename_metadata(filePath)\n",
    "        text = \"\"\n",
    "\n",
    "        if file.endswith(\".pdf\"):\n",
    "            print(\"PDF\")\n",
    "            pdfStruct = extractSelectorPdf(filePath)\n",
    "            text = getJustTextFromPdf(pdfStruct)\n",
    "\n",
    "            \n",
    "        elif file.endswith(\".vtt\"):\n",
    "            print(\"SUBTITULOS\")\n",
    "            text = getTextFromVtt(filePath)\n",
    "\n",
    "        uploadQdrantFromText(text, embedder, qdrant, collection_name, metadata, conf.PAGE_IDENTIFIER_RE)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI embedder\n",
    "embedder = AzureOpenAIEmbeddings(\n",
    "    api_key= conf.AZURE_OPENAI_API_KEY,             \n",
    "    azure_endpoint=conf.AZURE_OPENAI_ENDPOINT,  \n",
    "    deployment=conf.AZURE_EMBEDDINGS_MODEL          \n",
    ")\n",
    "\n",
    "# Initialize OpenAI model endpoint\n",
    "client = AzureOpenAI(    \n",
    "    api_key=conf.AZURE_OPENAI_API_KEY,\n",
    "    api_version=conf.AZURE_LLM_VERSION,\n",
    "    azure_endpoint=conf.AZURE_LLM_ENDPOINT\n",
    ")\n",
    "\n",
    "# Initialize vector database\n",
    "qdrant = QdrantClient(\n",
    "    url = conf.QDRANT_API_URL, \n",
    "    api_key = conf.QDRANT_API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROCESANDO 1/3: 000375_11_Manual_operativo_My_WORLD_v2.pdf\n",
      "PDF\n",
      "\t\tPROCESADO NORMAL\n",
      "PROCESANDO 2/3: Mediolanum My World_P63.pdf\n",
      "PDF\n",
      "\t\tPROCESADO NORMAL\n",
      "PROCESANDO 3/3: transcripcion.vtt\n",
      "SUBTITULOS\n"
     ]
    }
   ],
   "source": [
    "extractDataFromDir(\"..\\\\data\", embedder, qdrant, conf.QDRANT_COLLECTION_NAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvMediolanum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
